---
title: "Final Report"
output: pdf_document
date: "`r Sys.Date()`"
bibliography: References.bib
nocite: '@*'
---

```{=tex}
\newpage 
\tableofcontents 
\newpage
```
# Introduction

Machine learning techniques have become increasingly popular and relevant to solve text and sentiment-related problems in recent years. It has boosted performance on several tasks and significantly reduced the necessity for human efforts. For this project, we focused on text classification, especially sentiment analysis, on two datasets, *Amazon Review* and *Drug Review*. While the *Amazon Review* dataset is popular and was being used for many research papers and projects, we decided to replicate the code of four classic machine learning models from existing literature and adapted them to a newer but less popular dataset we found in the UCI Machine Learning Repository. Our goal for the project is to compare classifiers including \verb|BoW|, \verb|Word2Vec|, \verb|GloVe|, \verb|fastText| for two different datasets. 

# Dataset Overview & Preporcess
For the *Amazon Review* dataset, we used the same dataset mentioned by @AmazonData, which was obtained from the link provided by @rCode^[Google Drive Link: https://drive.google.com/drive/u/0/folders/0Bz8a_Dbh9Qhbfll6bVpmNUtUcFdjYmF2SEpmZUZUcVNiMUw1TWN6RDV3a0JHT3kxLVhVR2M]. The dataset contains about 1,800,000 training samples and 200,000 testing samples with three attributes, which are classification labels (1 for negative reviews and 2 for positive reviews), the title of each review text, and the review text body. Due to the limit of computer computation ability, we pulled out the first 100,000 data samples and split 80% of the data into the training set and 20% of the data into the testing set. Below are the head rows from the data:
``` {r amazon head}
```
For the Drug dataset, we downloaded from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29). The dataset has 215,063 samples with 6 attributes, including \verb|drugName|, \verb|condition|, \verb|review|, \verb|rating| (1 to 10), \verb|date|, \verb|usefulCount|. Similar to *Amazon Review* dataset, we split the whole dataset into training (80%) and testing (20%) datasets. In order to replicate the code, we categorized the dataset into two labels, where \verb|rating|s range from [need to be filled] are categorized as [1(negative) or 2(positive)] and the rest is categorized as []. Moreover, we only retained three columns (i.e., \verb|review|, \verb|rating|, [\verb|condition|]) to make the dataset have the same format as *Amazon Review*. Below are the head rows of the preprocessed data:
``` {r drug head}
```



# Model 1: Bag of Words with Naive Bayes algorithm
Bag of Words (BoW) method is widely used in NLP and computer vision fields. It takes the occurrence of each word in the text regardless of grammar and makes it into “bags” to characterize the text. To implement BoW method for our dataset, *Amazon Review* and Drug dataset, we first use \verb|VCorpus| function and \verb|DocumentTermMatrix| function in the \verb|tm| package to convert text into a matrix. By adjusting the built-in parameter in the  \verb|DocumentTermMatrix|, we do not have to worry about cleaning the dataset with stop words and punctuation. In order to make the model more precise, we removed words that do not occur in 99% of the documents by using \verb|removeSparseTerms| function. After finishing the process of BoW conversion, we followed @rCode and used the Naive Bayes sentiment classifier to perform predictions. Utilizing the \verb|nb_sent_classifier| in the \verb|e1071| package, we obtained the prediction results with [accuracy] for *Amazon Review* data and [accuracy] for Drug data.  


# References

<!-- ```{r setup, include=FALSE} -->

<!-- knitr::opts_chunk$set(echo = TRUE) -->

<!-- ``` -->

<!-- ## R Markdown -->

<!-- This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>. -->

<!-- When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this: -->

<!-- ```{r cars} -->

<!-- summary(cars) -->

<!-- ``` -->

<!-- ## Including Plots -->

<!-- You can also embed plots, for example: -->

<!-- ```{r pressure, echo=FALSE} -->

<!-- plot(pressure) -->

<!-- ``` -->

<!-- Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot. -->
